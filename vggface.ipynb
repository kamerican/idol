{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR = Path(__file__).parent.parent\n",
    "# BASE_DIR = Path.cwd().\n",
    "DRIVE_NAME = \"F:\\\\\"\n",
    "DATA_DIR = Path(DRIVE_NAME).joinpath('data')\n",
    "IMAGE_DIR = DATA_DIR.joinpath('images')\n",
    "DUMP_DIR = DATA_DIR.joinpath('dump')\n",
    "MODEL_DIR = DATA_DIR.joinpath('models')\n",
    "# for c in DATA_DIR.iterdir(): print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [<tf.Tensor 'input_4:0' shape=(None, 224, 224, 3) dtype=float32>]\n",
      "Outputs: [<tf.Tensor 'global_average_pooling2d_17/Mean:0' shape=(None, 2048) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "mtcnn_face_detector = MTCNN()\n",
    "# vgg_embedding_extractor = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "vgg_embedding_extractor = VGGFace(model='senet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "print('Inputs: %s' % vgg_embedding_extractor.inputs)\n",
    "print('Outputs: %s' % vgg_embedding_extractor.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidImage",
     "evalue": "Image not valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidImage\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aa70c31c919f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     print(image.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmtcnn_face_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#     print(len(faces))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mface_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Miniconda3\\envs\\idol_env\\lib\\site-packages\\mtcnn\\mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image not valid.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidImage\u001b[0m: Image not valid."
     ]
    }
   ],
   "source": [
    "test_dir = IMAGE_DIR.joinpath('2010-09-27')\n",
    "\n",
    "images_list = []\n",
    "\n",
    "embeddings_list = []\n",
    "# index = 0\n",
    "for image_path in test_dir.iterdir():\n",
    "    image_dict = {\n",
    "        'path': image_path,\n",
    "        'face_list': [],\n",
    "    }\n",
    "#     print(image_path)\n",
    "    # index += 1\n",
    "    image = cv2.imread(str(image_path))\n",
    "#     print(image.shape)\n",
    "    \n",
    "    faces = mtcnn_face_detector.detect_faces(image)\n",
    "#     print(len(faces))\n",
    "    face_index = 0\n",
    "    for face_dict in faces:\n",
    "        \n",
    "        \n",
    "        face_index += 1\n",
    "        confidence = face_dict['confidence']\n",
    "#         print(confidence)\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "        (x, y, width, height) = face_dict['box']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get face image from bounding box and preprocess\n",
    "        face_image = image[y:y + height, x:x + width]\n",
    "        face_image = cv2.resize(face_image, (224, 224))\n",
    "        face_image_window = '{}'.format(face_index)\n",
    "        cv2.imshow(face_image_window, face_image)\n",
    "        cv2.moveWindow(face_image_window, 224*(face_index - 1), 0)\n",
    "        \n",
    "        # Draw bounding box\n",
    "        image = cv2.rectangle(\n",
    "            image,\n",
    "            (x, y),\n",
    "            (x + width, y + height),\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "        \n",
    "        samples = preprocess_input(np.expand_dims(face_image.astype('float32'), axis=0), version=2)\n",
    "        embedding = vgg_embedding_extractor.predict(samples)\n",
    "        \n",
    "        face_data_dict = {\n",
    "            'source_image_path': image_path,\n",
    "            'mtcnn_extraction': face_dict,\n",
    "            'vgg_extraction': embedding,\n",
    "        }\n",
    "        image_dict['face_list'].append(face_data_dict)\n",
    "    images_list.append(image_dict)\n",
    "    cv2.imshow('test image', image)\n",
    "    cv2.moveWindow('test image', 0, 224)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_dir.joinpath(test_dir.name + '.pkl'), 'wb') as save_path:\n",
    "    pickle.dump(images_list, save_path)\n",
    "    \n",
    "    \n",
    "# np.linalg.norm(embeddings_list[0] - embeddings_list[0], ord=2)\n",
    "# cosine(embeddings_list[6], embeddings_list[7])\n",
    "\n",
    "# with open(test_dir.joinpath(test_dir.name + '.pkl'), 'rb') as load_path:\n",
    "#     asdf = pickle.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
